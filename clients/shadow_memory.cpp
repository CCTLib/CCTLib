// @COPYRIGHT@
// Licensed under MIT license.
// See LICENSE.TXT file in the project root for more information.
// ==============================================================

#include<stdint.h>
#include<atomic>

// 64KB shadow pages
#define PAGE_OFFSET_BITS (16LL)
#define PAGE_OFFSET(addr) ( addr & 0xFFFF)
#define PAGE_OFFSET_MASK ( 0xFFFF)
#define PAGE_SIZE (1 << PAGE_OFFSET_BITS)

// 2 level page table
#define PTR_SIZE (sizeof(struct Status *))
#define LEVEL_1_PAGE_TABLE_BITS  (20)
#define LEVEL_1_PAGE_TABLE_ENTRIES  (1 << LEVEL_1_PAGE_TABLE_BITS )
#define LEVEL_1_PAGE_TABLE_SIZE  (LEVEL_1_PAGE_TABLE_ENTRIES * PTR_SIZE )

#define LEVEL_2_PAGE_TABLE_BITS  (12)
#define LEVEL_2_PAGE_TABLE_ENTRIES  (1 << LEVEL_2_PAGE_TABLE_BITS )
#define LEVEL_2_PAGE_TABLE_SIZE  (LEVEL_2_PAGE_TABLE_ENTRIES * PTR_SIZE )

#define LEVEL_1_PAGE_TABLE_SLOT(addr) ((((uint64_t)addr) >> (LEVEL_2_PAGE_TABLE_BITS + PAGE_OFFSET_BITS)) & 0xfffff)
#define LEVEL_2_PAGE_TABLE_SLOT(addr) ((((uint64_t)addr) >> (PAGE_OFFSET_BITS)) & 0xFFF)

#define SHADOW_STRUCT_SIZE (sizeof (T))

namespace ShadowMemory {
    // All fwd declarations
    static uint8_t ** gL1PageTable[LEVEL_1_PAGE_TABLE_SIZE];
    static bool falseVal(false);
    
    static volatile atomic<bool> gShadowPageLock(false);
    static inline VOID TakeLock(volatile atomic<bool> * myLock) {
        do{
            while(myLock->load(memory_order_acquire) == true);
        }while(!myLock->compare_exchange_strong(falseVal,true));
    }
    
    static inline VOID ReleaseLock(volatile atomic<bool>  * myLock){
        myLock->store(false, memory_order_release);
    }
    
    // Given a address generated by the program, returns the corresponding shadow address FLOORED to  PAGE_SIZE
    // If the shadow page does not exist a new one is MMAPed
    template <class T>
    static inline T * GetOrCreateShadowBaseAddress(void const * const address) {
        T * shadowPage;
        uint8_t  *** l1Ptr = &gL1PageTable[LEVEL_1_PAGE_TABLE_SLOT(address)];
        if ( *l1Ptr == 0) {
            TakeLock(&gShadowPageLock);
            // If some other thread created L2 page table in the meantime, then let's not do the same.
            if (*l1Ptr == 0) {
                *l1Ptr =  (uint8_t **) calloc(1,LEVEL_2_PAGE_TABLE_SIZE);
            }
            // If some other thread created the same shadow page in the meantime, then let's not do the same.
            if(((*l1Ptr)[LEVEL_2_PAGE_TABLE_SLOT(address)]) == 0 ) {
                (*l1Ptr)[LEVEL_2_PAGE_TABLE_SLOT(address)] =  (uint8_t *) mmap(0, PAGE_SIZE * SHADOW_STRUCT_SIZE, PROT_WRITE | PROT_READ, MAP_NORESERVE | MAP_PRIVATE | MAP_ANONYMOUS, 0, 0);
            }
            ReleaseLock(&gShadowPageLock);
        } else if(((*l1Ptr)[LEVEL_2_PAGE_TABLE_SLOT(address)]) == 0 ){
            TakeLock(&gShadowPageLock);
            // If some other thread created the same shadow page in the meantime, then let's not do the same.
            if(((*l1Ptr)[LEVEL_2_PAGE_TABLE_SLOT(address)]) == 0 ) {
                (*l1Ptr)[LEVEL_2_PAGE_TABLE_SLOT(address)] =  (uint8_t *) mmap(0, PAGE_SIZE * SHADOW_STRUCT_SIZE, PROT_WRITE | PROT_READ, MAP_NORESERVE | MAP_PRIVATE | MAP_ANONYMOUS, 0, 0);
            }
            ReleaseLock(&gShadowPageLock);
        }
        shadowPage = (T *)((*l1Ptr)[LEVEL_2_PAGE_TABLE_SLOT(address)]);
        return shadowPage;
    }
    
    template <class T>
    static inline T * GetOrCreateShadowAddress(void * address) {
        T * shadowPage = GetOrCreateShadowBaseAddress<T>(address);
        return shadowPage + PAGE_OFFSET((uint64_t)address);
    }
}
